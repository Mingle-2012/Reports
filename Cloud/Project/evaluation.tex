\section{Evaluation}
\label{sec:evaluation}

In this section, we evaluate the performance of our MapReduce framework using various test cases. We first describe the experimental setup in Section~\ref{subsec:experimental-setup}, then present the results of local test cases in Section~\ref{subsec:local-test-cases}, and finally discuss the results of cluster test cases in Section~\ref{subsec:cluster-test-cases}.

\subsection{Experimental Setup}
\label{subsec:experimental-setup}

In this part, we describe the experimental setup used to evaluate the performance of the implemented MapReduce framework. For the local test cases, we run the framework on a single machine with multiple threads. It is equipped with an Intel Core i7-12700H CPU, 32 GB of RAM, and a 2 TB SSD. The software environment ran on Ubuntu 22.04 LTS in Windows Subsystem for Linux (WSL) 2.0., with Java being the primary programming language. We use JDK 21 for compiling and running the code, gRPC 1.68.0 for communication between the master and worker nodes, and JUnit 4.13.2 for testing. For the cluster test cases, we deploy the framework on the aforementioned local machine, deploying multiple worker nodes as separate docker containers. Each worker node runs on a separate thread, simulating a distributed environment. We use Docker 26.1.1 for containerization.

\subsection{Datasets}

We use two datasets for the evaluation of the MapReduce framework: a small dataset and a large dataset. The small dataset contains 1,000,000 words, while the large dataset contains 10,000,000 words. Both datasets are generated randomly and stored in text files. The input data is split into multiple chunks for parallel processing by the mappers. The intermediate key-value pairs are shuffled and reduced to generate the final output. The datasets are used to evaluate the performance of the WordCount application and other test cases.

\subsection{Local Test Cases}
\label{subsec:local-test-cases}

In this part, we present the results of the local test cases conducted on the implemented MapReduce framework. 

\subsubsection{WordCount Application}

We first evaluate the performance of the WordCount application, a classic example in the MapReduce model. The WordCount application counts the frequency of each word in a given text file. We use a sample text file containing 1,000,000 words for this test case. The input data is split into 16 chunks, and each chunk is processed by a mapper. The intermediate key-value pairs are shuffled and reduced to generate the final word count. We measure the execution time of the WordCount application using different numbers of mappers and reducers. The results are shown in Table~\ref{tab:wordcount}.

\begin{table}[h]
    \centering
    \caption{Performance of the WordCount application with different numbers of mappers and reducers.}
    \label{tab:wordcount}
    \begin{tabular}{|c|c|c|}
        \hline
        \textbf{Mappers} & \textbf{Reducers} & \textbf{Execution Time (s)} \\
        \hline
        1 & 1 & 10.23 \\
        2 & 2 & 5.67 \\
        4 & 4 & 3.45 \\
        8 & 8 & 2.12 \\
        16 & 16 & 1.34 \\
        \hline
    \end{tabular}
\end{table}




\subsection{Cluster Test Cases}
\label{subsec:cluster-test-cases}